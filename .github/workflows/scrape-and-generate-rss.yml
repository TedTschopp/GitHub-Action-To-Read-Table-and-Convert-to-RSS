name: Scrape Table and Generate RSS Feed

on:
  schedule:
    # Run every 8 hours at minute 0
    - cron: '0 */8 * * *'
  workflow_dispatch:
    # Allow manual triggering

jobs:
  scrape-and-generate-rss:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    outputs:
      rss-updated: ${{ steps.check-changes.outputs.changes-detected }}
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run scraper and generate RSS
      run: python scrape_to_rss.py
      env:
        CHROME_BIN: /usr/bin/chromium-browser
        DEBUG: "true"
      
    - name: Run RSS health monitoring
      run: python monitor.py
      
    - name: Check for RSS changes
      id: check-changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add all RSS files and status report
        git add ai_rss_feed.xml eei_ai_rss_feed.xml rss_status.json previous_data.json
        
        if git diff --staged --quiet; then
          echo "No changes to commit"
          echo "changes-detected=false" >> $GITHUB_OUTPUT
        else
          echo "Changes detected, committing..."
          git commit -m "Update RSS feeds and status report - $(date -u)"
          git push
          echo "changes-detected=true" >> $GITHUB_OUTPUT
        fi
